#### configuration and directory
CONFIG_NAME: Train 
dataset_name: face2text 
data_dir: ./data/face2text  
checkpoints_path: ./checkpoints

weights_adaface: "./weights/pretrained/adaface_ir18_webface4m.ckpt"
weights_arcface: "./weights/pretrained/arcface_ir18_ms1mv3.pth"
weights_magface: "./weights/pretrained/magface_iresnet18_casia_dp.pth"
valid_pair_list: ./data/face2text/images/valid_199_sub.txt 

# machine setup
num_workers: 8 
gpu_id: [0] #1
manual_seed: 100
CUDA: True

# losses
is_DAMSM: True       
is_CLIP: True        
is_CMP: False 
is_WRA: False  
is_ident_loss: True      
lambda_clip: 2.0
lambda_id:  100

# model arch 
aux_feat_dim_per_granularity: 256
img_size: 112 
model_type: arcface #arcface, magface, adaface     
ch_size: 3           
num_classes: 4500 

init_lr_bert: 0.00007  #(7e-5) initial learnig rate 
min_lr_bert: 0.00002)
lr_head: 0.001
weight_decay: 0.01 #0.01 for BERT
clip_max_norm: 1.0

#trainng settings
batch_size: 32 #32
max_epoch: 20
test_interval: 2
save_interval: 1
temperature: 2.0

# flags
do_test: False   

# encoder
TRAIN:
    FLAG: True
    SMOOTH:
        GAMMA1: 4.0  
        GAMMA2: 5.0
        GAMMA3: 10.0
      
en_type: "BERT"   
bert_words_num: 24
captions_per_image: 4 #4, 10 

bert_type: "bert" 
bert_config:  bert-base-uncased 
align_config: kakaobrain/align-base
clip_config: openai/clip-vit-base-patch32
blip_config: Salesforce/blip-image-captioning-base
falva_config: facebook/flava-full
groupvit_config: nvidia/groupvit-gcc-yfcc