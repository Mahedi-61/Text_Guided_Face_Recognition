CONFIG_NAME: Fusion
dataset_name: celeba
data_dir: ./data/celeba
test_pair_list: ./data/celeba/celeba/celeba_valid_pair.txt  
checkpoints_path: ./checkpoints
load_model_path: ./weights/celeba/FE/resnet18_celeba_110.pth
resume_model_path: ./weights/celeba/Fusion/bert_cross_attention_epoch_.pth
text_encoder_path: "./weights/celeba/Fusion/arcface_text_encoder_bert_7.pth"
resume_epoch: 1

# machine setup 
num_workers: 6 
gpu_id: [0, 1]
manual_seed: 100
cuda: True

# model arch
img_size: 128
model_type: arcface
ch_size: 1

backbone: resnet18
classify: softmax
num_classes: 24000 
metric: arc_margin 
easy_margin: False
loss: focal_loss 
optimizer: sgd 
use_se: False


# training settings 
lr_image_train: 0.01   #0.01 for ArcFace
lr_step: 4
gamma: 0.5  
weight_decay: 0.0005
lr_head: 0.001
patience: 2 
factor: 0.70
temperature: 1.0

max_epoch: 28
batch_size: 16
test_interval: 1
save_interval: 1
trainable: False

# fusion arch
fusion_type: cross_attention #cross_attention, linear, paragraph_attention, concat
fusion_final_dim: 768  
aux_feat_dim_per_granularity: 64

#save
roc_file: arc_mcfanet

# flags
do_test: True

# encoder settings
rnn_type: LSTM #GRU 
using_BERT: True    
en_type: "bert"     
bert_words_num: 21
lstm_words_num: 18 
bert_config:  bert-base-uncased #distilbert-base-uncased  
embedding_dim: 256
captions_per_image: 10